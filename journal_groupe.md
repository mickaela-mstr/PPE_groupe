#Journal de bord du projet en groupe

##Intro : Comment se sont déroulées les séances en cours

(Mickaëla) Fin novembre, début décembre nous avons commencé à nous pencher sérieusement sur le projet de fin de semestre en cours. Le choix des mots et des langues a été la première étape. Nous avons décidé de nous concentrer sur le mot "légende" en français, donc "legend" en 'anglais et "أسطورة" pour l'arabe. Ce mot nous a paru être un choix adéquat pour l'analyser, car il porte plusieurs sens dans chacune des langues. Que ce soit en français, en anglais ou en arabe, il évoque des récits, des mythes, mais aussi un sens en géographie ou a un sens figuré ou selon les contextes.

Le choix de ces trois langues était assez simple pour notre groupe. J'ai étuidé l'anglais pendant 3 ans en licence donc je pense être assez à l'aise pour pouvoir travailler dessus. En plus, c'est une langue internationale, ce qui je pense peut faciliter pour les recherches d'URLs car la langue la plus commune pour le contenu sur le web c'est l'anglais. Le français, c'est la langue obligatoire pour le projet donc pas le choix de l'avoir ^^. Mais c'est aussi un avantage car ça nous offre un terrain familier pour aborder les différents sens du mot. Enfin, l'arabe, c'est une langue que Zeineb et Oumaya maîtrisent ce qui élargit notre perspective et nous confronte à d'autres manières d'analyser le concept de "légende". On peut dire que nos choix reflètent aussi nos parcours variés en tant qu'étudiantes.

La préparation de ce projet a commencé par une phase de recherche et d'organisation. Grâce à la fiche 8, on a pu tructurer les données que nous allions recueillir dans des dossiers suivant l'arborescence donnée. Une angoisse qui m'est tout de suite venue est la gestion des conflts sur git qui est quelque chose que je n'arrive pas toujours à maîtriser :(. Mais nous savions dès le départ que cela nécessiterait une approche méthodique et des échanges constants entre nous pour éviter le plus possible ces situations. On a un groupe sur Whatsapp où on se prévient à chaque fois que quelqu'un push des changements ce qui est super pratique.

Personnellement, la période avant les vacances a été assez rude en termes de travail personnel et de révisions pour les partiels, ce qui m'a empêchée de me mettre sérieusement sur le projet en PPE (pardoon :( ). J'ai pu démarrer les exercices sur les scripts d'aspiration et de dump textuel en cours en m'aidant de ce qu'on avait déjà vu en cours par le passé, notamment avec la commande lynx et curl. J'ai aussi conservé le script crée lors du miniprojet individuel pour le traitement des urls invalides avec leur code HTTP. Mais je me suis mise de manière assidue sur le projet après les fêtes de noël.

(Oumaya)

Le 27/12/2024
(Mickaëla) En pleine nuit parce que je stressais,
Après les fêtes je ne me rappelais d'absolument plus rien de ce que j'avais fait en cours donc j'ai stressé. Et après quand j'avais fini de stresser, j'ai récupéré quelques urls en anglais pour pouvoir tester les scripts que j'avais fait auparavant. Ils fonctionnaient! Après je suis partie dormir. Oui c'est pas grand chose mais voilà :)

Le 28/12/2024
(Mickaëla) J'étais moins stressée du coup plus apte à travailler plus longtemps cette fois :) Pour éviter de me mélanger les pinceaux, j'ai décidé de d'abord faire un script par langue pour les aspirations et les dumps, même si c'était la même chose à chaque fois je trouvais qu'au début c'était plus clair. J'ai enchaîné avec le script pour les contextes et là ça commençait à faire beaucoup dans le dossier programmes et c'était plus très clair...  Dans l'optique de rendre quelque chose de propre, j'ai décidé de rassembler chaque scripts pour qu'ils traitent chaque langue à chaque fois. Le problème pour moi à été de faire un script pour toutes les langues en même temps pour les contextes. En effet les aspirations et les dumps étaient assez simples à rassembler avec des boucles for et while sur chaque fichiers de chaque langue car les scripts d'aspiration et de dump suivent une logique assez similaire... Ils utilisent une boucle for pour parcourir les langues. Et à l'intérieur de chaque langue, une boucle while lit chaque ligne du fichier d'URLs correspondant à cette langue. Et au début, c'est ce que j'ai fait aussi pour les contextes et je suis partie me coucher comme ça...

Le 29/12/2024
(Mickaëla) Assez sereine je me réveille et je teste mon script pour les contextes, et là: c'est le drame!!!!! J'ai le fichier qui a été correctement généré en français, puis je vois absolument rien en arabe et en anglais... Et c'est là que les neurones se connectent, le mot légende s'écrit pas pareil en fonction de la langue... Et oui c'est évident dit comme ça mais fallait y penser! Du coup, je ne savais pas trop comment m'y prendre pour faire que le script reconnaisse les trois mots pour chaque langue. J'ai pensé à faire une expression régulière, ce qui pourrait fonctionner avec l'anglais et le français mais je savais vraiment pas comment faire pour le mot en arabe... J'étais bloquée, du coup j'avoue, j'ai utilisé ChatGPT... Et j'ai découvert qu'on pouvait faire un dictionnaire en bash comme en Python!!! Du coup c'est ce que j'ai utilisé pour reconnaître les mots pour chaque langue. Donc le dictionnaire associe chaque langue à son mot clé correspondant ce qui adapte automatiquement le mot recherché en fonction de la langue traitée. Et après pour chaque langue je récupère le dump et j'applique grep dessus avec PLEIN d'options parce que sinon y'avait toujours un soucis... -a qui force à traiter les fichiers comme du texte brut. -i (le classique) qui ignore la casse. -C 1 qui affiche une ligne de contexte avant et après chaque occurrence trouvée. Au début comme je traitais chaque url dans le même fichier on y voyait rien car tous les urls étaient à la suite du coup j'ai mis sed pour mettre en évidence avec des chevron chaque occurence du mot légende dans chaque langue.

Le 30/12/24
(Mickaëla) La mission de ce jour a été de faire qu'il y ait un fichier par URL pour chaque script, car comme la fiche d'exercice l'indiquait, après avoir crée les scripts il fallait mettre les résultats dans une nouvelle colonne dans le tableau. Et dans cette colonne il devait y avoir un lien pour chaque fichier résultat (la page aspirée, son dump, son contexte etc...). Alors je trouvais ça bizarre d'avoir 50 fois le même lien vers le même fichier et de devoir scroller à l'infini pour voir l'url correspondant...  Il fallait donc  créer un fichier distinct pour chaque URL, en utilisant un index numérique pour les identifier. On établit donc un compteur dans la boucle qui s'incrémente de 1 pour chaque URls traitée. Après il fallait générer les tableaux donc j'ai gardé la structure initiale de l'exercice du miniprojet individuel avec les codes http, l'encodage etc, et j'ai rajouté les colonnes nécessaires. Une question qui m'est venue concernait l'affichage des fichiers .txt tels que les dumps et les contextes dans un navigateur web. Je pensais qu'il fallait les convertir en html mais je n'étais pas sûre que ce soit la bonne chose à faire. Puis j'ai demandé à une M2 de m'expliquer comment elle s'y était prise l'an dernier et en fait les fichiers textes s'affichent aussi dans le web... Donc oui je me prenais la tête pour rien :)

Le 31/12/2024 (Mickaëla) Avant le réveillon du nouvel an, j'ai continué le travail de la veille en modifiant les scripts aspirations, contextes, concordancier pour avoir un fichier par url puis j'ai modifié le script générant les tableaux pour qu'ils affichent le fichier correspondant à leur url. Je me suis ensuite attaquée aux exercices PALS. La difficulté majeure a été de créer un script rendant les corpus dumps et contextes adaptés au traitement textométrique des scripts cooccurrents et partition. La tokenisation a été assez simple avec [[:alpha:]] qui reconnait tous les caractères ASCII de l'anglais, mais le soucis majeur résidait dans les problèmes d'encodage/regex pour le français et l'arabe. En effet, mon éditeur de texte ne reconnaissait pas les caractères diacrités du français et les caractères de l'arabe malgré la lecture des fichiers en UTF-8 qui fonctionnent normalement avec ces deux langues. J'ai demandé à Ihsane (étudiante de notre promo) et une m2, Kehina (merci à elles) de m'aider par rapport à ce soucis. Elles m'ont aiguillé en me proposant plusieurs regex pour reconnaître les caractères arabes: ا-ي. et أسطورة|أسطورات|أسطورتين|الأسطورة|الأسطورات|الأسطورتين et pour le français accentués : a-zàâçéèêëîïôûùüÿñæœ. Mais cela ne fonctionnait pas. J'ai donc décidé de régler ce soucis pour l'année prochaine :)

Le 1/01/2025 (Mickaëla) BONNE ANNEE 2025!!!!!!!!!! Rien de mieux pour fêter ça que de galérer sur des problèmes d'encodage et de regex :). Non je rigole, j'étais trop fatiguée pour me battre avec ça dès le réveil donc j'ai considéré que c'était un problème pour la moi de plus tard. J'ai avancé un peu en testant le script PALS sur le corpus de ma langue qui est le seul pour qui la tokenisation a fonctionné. J'ai regardé les consignes d'utilisations du script avec -h et j'ai joué un peu avec. J'ai vu qu'on pouvait émuler itrameur avec le script. Alors je ne suis pas une grande linguiste donc j'avoue que je ne comprenais pas tout au résultat mais je savais qu'itrameur était un outil utilisé par les promos des années précédentes donc j'ai décidé de tester moi aussi pour l'analyse. Puis je me suis remise sur le problème des regex/encodage.. Pour une raison obscure j'ai commencé à me dire que c'était peut être un problème avec les scripts dumps et contextes... J'ai donc vérifié et je me suis rendue compte d'un autre problème, les contextes ne récupèrent que le singulier "legend" pareil pour le français et je suppose pareil pour l'arabe (je sais pas lire l'arabe :/). Ce qui est bizarre c'est que lorsque je lançais grep sur le terminal, ça fonctionnait à moitié... Bref trop de problèmes j'ai donc décdié de me lancer sur d'autres projet à rendre dans d'autres matières pour la semaine qui a suivi.

Le 8/01/2025 (Mickaëla) De retour sur PPE après une semaine de souffrance sur d'autres projets :(. Toujours le même soucis sur la tokenisation du corpus français et arabe... Avant j'essaie de quand même de régler le soucis avec grep dans le script contexte en le remplaçant par egrep car dans le terminal egrep reconnaissait la regex legends? et légendes?. Mais une fois dans le script, quand je le lançais puis que je lançais le concordancier j'avais toujours le contexte droit qui me donnait un "s" en premier mot... Alors en soit j'ai quand même la ligne d'après, mais je trouve ça un peu dommage car la commande fonctionne vraiment dans le terminal avec le français et l'anglais en tout cas.. J'abandonne le sujet pour retourner sur la tokenisation, je suis désespérée je trouve pas de soluce donc je fais à appel à ChatGPT qui me propose la commande perl sauf que j'y comprends rien donc j'abandonne vite ce sujet aussi... Finalement je me lance dans l'amélioration du site qui est une partie mafoi très satisfaisante et esthétique. J'ai rajouter une page à propos pour donner des informations sur les membres du projet. J'ai cherché comment rajouter un menu déroulant puis je l'ai ajouté aux balise. Je commence la rédaction de la présentation etc... Voilà pour ce jour.

Le 9/01/2025 (Mickaëla) Prise d'un élan d'énergie dans la nuit du 8 au 9 j'ai décidé de compléter ma liste d'urls! Puis j'ai repris l'analyse linguistique dans la journée. Grâce à Ihsane, j'ai découvert l'outil voyant tools qui permet de faire des nuages de mots interactifs! C'est super joli donc j'ai voulu tester sur mes corpus. Or, il y avaient plusieurs soucis (c'est pas drôle sinon), d'abord le site n'acceptaient pas ni mes dumps ni mes contextes. Ils se trouvaient que certain de mes fihciers avaient des données non textuelles . J'ai utilisé la commande file dans mon terminal pour identifier les fichiers posant problème (ça m'indiquait data dans le terminal) et il se trouvait qu'il y avait deux lien qui n'était pas des fichier de type html ou txt. J'ai donc remplacé les urls posant problème. Puis j'ai eu le soucis des "parasites" dans mon nuage qui rendait le tout assez peu pertinent. Cela correspondaient à tout ce qui est "autour" du sujet principal du site par exemple si c'est un article,les liens vers d'autres articles, les liens vers d'autres pages wikipedia etc... Donc j'ai essayé de trouvé des techniques pour nettoyer les fichiers aspirations ou dump avec sed par exemple : echec car il n'y avait pas qu'une forme récurrente de données parasites, mais tout plein et je savais pas comment en faire une expression à reconnaître... ChatGPT m'a proposé des commandes comme html2text : ça marche pas. Je me suis rappelée de la commande awk qu'on a mentionnée en cours mais j'ai cru comprendre en cours que c'est un truc pour les grands donc j'ai pas osé utiliser. Finalement j'ai juste cat * les résultats du script dump et j'ai essayé d'enlever les données à la main le plus possible... C'était LONG. Mais ça a plus ou moins marché car maintenant mon nuage est tout beau :). J'ai continué à essayer de régler le soucis des contextes et de tokenisation, sans résultats :(. J'ai aussi rajouté des pages manquantes comme le journal et l'analyse linguistique dans le site etc...

Le 10/01/2025 (Mickaëla)</h6>Aujourd'hui, je me suis attelée à l'interprêtation et à la rédaction des résultats des scripts cooccurrent et partition. La difficulté ici a été d'utiliser le script partition pour les contextes car cela me disait qu'il n'y avait pas assez de données? Ce qui est bizarre car pour les dumps je n'ai pas eu de soucis j'ai donc décidé de me concentrer sur les cooccurences. J'ai surtout fait de l'écriture et de la mise en forme des pages. J'ai aussi ajouté ma description dans le a propos du site.Il ne manque plus que d'ajouter la section scripts au site et de les expliquer et puis je pense que j'arrive à la fin de mon travail sur ce projet.

Le 11/01/2025 (Mickaëla) Alors il est 3h30 et je viens d'avoir une illumination par rapport au script contexte qui ne reconnait que legend au singulier! Peut être que le soucis n'est pas le script contexte au final mais le concordancier!!!! En effet comme egrep fonctionne dans le terminal, ça veut dire que mes contextes (et j'ai vérifié) ont bien soit legend ou legends. Or je vérifie toujours le concordancier sur le site car c'est plus simple de consulter ce tableau plutôt que de chercher dans le fichier texte de contexte. Et c'est là bas que je voyais le soucis!!!! Donc il est temps de jeter un oeil dessus #insomnie.

Zeinab : malheuresement, j'ai mal compris le concept du journal... je n'ai pas écrit tout les jours mais c'est pas grave... je vais vous récapituler mon parcours et mon ressenti durant ce travail... alors les taches à faire n'étais si évidentes que ça... j'avais pour taches dés le départ de faire la plupart des scripts dont (la validation des urls, concordancier et le make pals...) que mes collégues ont bien sur modifié au fur et à mesure du travail afin d'adapter à leur langues. malheuresement, je n'ai pas eu beaucoup de sources pour le mot légende en arabe d'ou le peu d'urls que j'ai, ce qui m'a beaucoup étonné car je ne m'attendais pas à ce que j'ai peu de ressources. je rencocntre acctuellement de gros problèmes de regex avec ce mots et d'encondage à cause du script make pals... c'est un peu la panique je ne vais pas vous mentir parce que cela m'empeche à faire mon analyse linguistique, j'essaye de trouver une solution depuis un moment... si ça ne marche toujours pas je me contenterai que de voyant tools...j'ai créée également une page web explicatif des script qui permet de mettre au clair tout notre travail. Je reconnais que le nombre de commits dans mon dépôt Git est relativement faible. Cependant, cela ne reflète pas pleinement le travail que j’ai accompli. J’ai rencontré des contraintes liées à un déplacement à l’étranger, ce qui m’a empêché de travailler régulièrement chaque jour. Malgré cette interruption, j’ai tenu mes engagements et accompli les tâches qui m’ont été assignées dans le cadre de la répartition convenue avec mes collègues.

