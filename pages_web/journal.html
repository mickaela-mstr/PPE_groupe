<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projet Légende</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma/css/bulma.min.css">
    <style>
        body {
            display: flex;
            min-height: 100vh;
            margin: 0;
            background: linear-gradient(135deg, #fdfcfb, #e2d1c3);
            color: #4a4a4a;
            font-family: 'Georgia', serif;
        }

        .sidebar {
            width: 250px;
            background-color: #f3c5b3;
            padding: 1rem;
            box-shadow: 2px 0 5px rgba(0, 0, 0, 0.1);
        }

        .sidebar a {
            display: block;
            padding: 0.8rem 1rem;
            margin-bottom: 1rem;
            background-color: #e8d6c3;
            color: #6b4226;
            font-weight: bold;
            text-decoration: none;
            border-radius: 8px;
            transition: background-color 0.3s;
        }

        .sidebar a:hover {
            background-color: #e2a68a;
            color: white;
        }

        .content {
            flex: 1;
            padding: 2rem;
        }

        .hero {
            background: url('./images/banner.jpg') no-repeat center center;
            background-size: cover;
            color: white;
            text-shadow: 0 2px 5px rgba(0, 0, 0, 0.3);
            padding: 4rem 1rem;
            position: relative;
            text-align: center;
        }

        .hero .hero-content {
            background: rgba(0, 0, 0, 0.6);
            padding: 2rem;
            border-radius: 10px;
            display: inline-block;
            margin: 0 auto;
        }

        .title {
            font-family: 'Playfair Display', serif;
            font-size: 2.5rem;
        }

        .subtitle {
            font-size: 1.2rem;
            color: #e8e8e8;
        }

        .section-title {
            color: #6b4226 !important;
            font-weight: bold;
            font-size: 2.5rem;
        }

        footer {
            background: #e8d6c3;
            padding: 1rem;
            text-align: center;
            font-size: 0.9rem;
            color: #6b4226;
        }

        .links {
            margin-top: 1rem;
        }

        .links a {
            color: #6b4226;
            font-weight: bold;
            text-decoration: none;
            margin-right: 1rem;
        }

        .links a:hover {
            text-decoration: underline;
            color: #e2a68a;
        }

        .has-submenu {
            position: relative;
        }

        .submenu {
            display: none;
            margin-top: 0.5rem;
            margin-left: 1rem;
        }

        .has-submenu:hover .submenu {
            display: block;
        }

        .submenu a {
            background-color: #f5e8df;
            margin-bottom: 0.5rem;
            display: block;
            padding: 0.8rem;
            border-radius: 8px;
            text-decoration: none;
        }

        .submenu a:hover {
            background-color: #e2a68a;
            color: white;
        }
    </style>
</head>
<body>
    <aside class="sidebar">
        <a href="indexv2.html">Accueil</a>
        <div class="has-submenu">
            <a href="#tableaux">Tableaux</a>
            <div class="submenu">
                <a href="../tableaux/anglais.html">Anglais</a>
                <a href="../tableaux/francais.html">Français</a>
                <a href="../tableaux/arabe.html">Arabe</a>
            </div>
        </div>
        <div class="has-submenu">
            <a href="#linguistique">Analyse Linguistique</a>
            <div class="submenu">
                <a href="analyse_linguistique_en.html">Anglais</a>
                <a href="../pages_web/analyse_linguistique_fr.html">Français</a>
                <a href="../pages_web/analyse_linguistique_ar.html">Arabe</a>
            </div>
        </div>
        <a href="script.html">Script</a>
         <a href="Journal.html">Journal</a>
        <a href="a_propos.html">À propos</a>
    </aside>

       <div class="content">
        <section id="linguistique" class="section">
            <div class="section-title-container">
                <h1 class="section-title">Journal</h1>
            </div>
                <p><h2 class="section-title">Journal de bord du projet en groupe Intro : Comment se sont déroulées les séances en cours</h2>

               <p><h6 class="section-title">(Mickaëla)</h6> Fin novembre, début décembre nous avons commencé à nous pencher sérieusement sur le projet de fin de semestre en cours. Le choix des mots et des langues a été la première étape. Nous avons décidé de nous concentrer sur le mot “légende” en français, donc “legend” en anglais et pour l'arabe أسطورة. Ce mot nous a paru être un choix adéquat pour l'analyser, car il porte plusieurs sens dans chacune des langues. Que ce soit en français, en anglais ou en arabe, il évoque des récits, des mythes, mais aussi un sens en géographie ou a un sens figuré ou selon les contextes. Le choix de ces trois langues était assez simple pour notre groupe. J'ai étuidé l'anglais pendant 3 ans en licence donc je pense être assez à l'aise pour pouvoir travailler dessus. En plus, c'est une langue internationale, ce qui je pense peut faciliter pour les recherches d'URLs car la langue la plus commune pour le contenu sur le web c'est l'anglais. Le français, c'est la langue obligatoire pour le projet donc pas le choix de l'avoir ^^. Mais c'est aussi un avantage car ça nous offre un terrain familier pour aborder les différents sens du mot. Enfin, l'arabe, c'est une langue que Zeineb et Oumaya maîtrisent ce qui élargit notre perspective et nous confronte à d'autres manières d'analyser le concept de “légende”. On peut dire que nos choix reflètent aussi nos parcours variés en tant qu'étudiantes. La préparation de ce projet a commencé par une phase de recherche et d'organisation. Grâce à la fiche 8, on a pu tructurer les données que nous allions recueillir dans des dossiers suivant l'arborescence donnée. Une angoisse qui m'est tout de suite venue est la gestion des conflts sur git qui est quelque chose que je n'arrive pas toujours à maîtriser :(. Mais nous savions dès le départ que cela nécessiterait une approche méthodique et des échanges constants entre nous pour éviter le plus possible ces situations. On a un groupe sur Whatsapp où on se prévient à chaque fois que quelqu'un push des changements ce qui est super pratique. Personnellement, la période avant les vacances a été assez rude en termes de travail personnel et de révisions pour les partiels, ce qui m'a empêchée de me mettre sérieusement sur le projet en PPE (pardoon :( ). J'ai pu démarrer les exercices sur les scripts d'aspiration et de dump textuel en cours en m'aidant de ce qu'on avait déjà vu en cours par le passé, notamment avec la commande lynx et curl. J'ai aussi conservé le script crée lors du miniprojet individuel pour le traitement des urls invalides avec leur code HTTP. Mais je me suis mise de manière assidue sur le projet après les fêtes de noël.</p>

               <p><h6 class="section-title">(Oumaya)</h6> Pendant les semaines des cours nous nous étions mis toutes trois d'accord pour choisir le mot légende dans les trois langues qui sont le français,l'anglais ainsi que l'arabe car ce mot nous a semblé adapté aux consignes qui nous demandaient de choisir un mot qui porte plusieurs sens dans chacune des langues. Que ce soit en français, en anglais ou en arabe, il évoque des récits, des mythes, mais aussi un sens de légende que le donne à une figure,un schémas et bien d'autres... Enfin bref ce mot à bien une multitude de sens. Et donc pour la répartition des langues nous avions decider que je m'occuperai du français car Mickaëla ayant fait une LEA Anglais était plus approprié pour faire en anglais et Zeinab ayant fait une licence d'arabe était plus aproprié pour s'occuper de la paertie arabe. De mon coté à part l'anglais et le français la seule autre langues que j'ai étudier de manière scolaire était l'alemand et n'en n'ayant pas fait depuis un bon long moment je ne me sentais pas à l'aise de faire en allemand. J'avais donc ensuite comencé au début à la suite de la création du dépot de groupe par créer les dossier et les fichiers nécessaire à partir de l'arborescence donné dans la fiche 8.J'ai ensuite mis les script que j'avais utiliser pour le dernier mini-projet qui pouvais potentiellement utile. Ensuite durant l'avant dernière séance j'ai créer une prmière version l'index de notre page car j'avais besoin de visualiser pour pouvoir savoir ce qu'on a fait ce qui manque etc... Pour l'esthétique de la page je m'étais grandement inspirée de ce que j'avais fait pour miniprojet. J'ai ensuite commencée à écrire des début de script car je savais que pendant les vacances j'allais avoir un bon moment d'absence dû à une opération médicale^^". J'ai commencé par les script compte et la difficulté de cette tâche à été de faire en sorte que toutes les formes de légende soit prises en compte (pluriels etc..).Et pour les script de concordance et contexte j'avais essayée de faire un début de script mais faute de temps je n'avais pas pû les finir.Et enfin j'avais commencé à chercher des URLs j'avais réussi à en récolter à peu près 10 juste histoire que je puisse au moins tester avec si les scripts marchait par la suite.  </p>

                <p><h6 class="section-title">Du 22/12/2024 au 30/12/2024 (Oumaya)</h6> Pendant cette pèriode je n'ai pas pu trop travailler que ce soit sur ce projet ou ceux des autres matières car j'été beaucoup trop dans le mal suite à mon opération. J'été sous de forts antidouleurs qui me mettaient Hors service 75% de la journée, (anti-douleurs codéiner) dès que j'en prenais j'avais une sensation de tourni et cela me forçait à m'endormir.J'étais êxtremement strésser pendant cette période car j'étais angoisser de ne pas pouvoir avancer sur mes projets mais le souci était que lorsque j'ai essée de travailler sur l'ordinateur cela me provoquait une sensation de nausée et je vomissais directemnt -.-"" . Vraiment une grosse pèriode d'angoisse. Donc je m'excuse pour cette pèriode où je ne peut pas vraiment de nouvelle chose que j'ai faite >.<"</p>


                <p><h6 class="section-title">Le 27/12/2024 (Mickaëla)</h6> En pleine nuit parce que je stressais, Après les fêtes je ne me rappelais d'absolument plus rien de ce que j'avais fait en cours donc j'ai stressé. Et après quand j'avais fini de stresser, j'ai récupéré quelques urls en anglais pour pouvoir tester les scripts que j'avais fait auparavant. Ils fonctionnaient! Après je suis partie dormir. Oui c'est pas grand chose mais voilà :)</p>

               <p><h6 class="section-title">Le 28/12/2024 (Mickaëla)</h6> J'étais moins stressée du coup plus apte à travailler plus longtemps cette fois :) Pour éviter de me mélanger les pinceaux, j'ai décidé de d'abord faire un script par langue pour les aspirations et les dumps, même si c'était la même chose à chaque fois je trouvais qu'au début c'était plus clair. J'ai enchaîné avec le script pour les contextes et là ça commençait à faire beaucoup dans le dossier programmes et c'était plus très clair... Dans l'optique de rendre quelque chose de propre, j'ai décidé de rassembler chaque scripts pour qu'ils traitent chaque langue à chaque fois. Le problème pour moi à été de faire un script pour toutes les langues en même temps pour les contextes. En effet les aspirations et les dumps étaient assez simples à rassembler avec des boucles for et while sur chaque fichiers de chaque langue car les scripts d'aspiration et de dump suivent une logique assez similaire... Ils utilisent une boucle for pour parcourir les langues. Et à l'intérieur de chaque langue, une boucle while lit chaque ligne du fichier d'URLs correspondant à cette langue. Et au début, c'est ce que j'ai fait aussi pour les contextes et je suis partie me coucher comme ça...</p>

               <p><h6 class="section-title">Le 29/12/2024 (Mickaëla)</h6> Assez sereine je me réveille et je teste mon script pour les contextes, et là: c'est le drame!!!!! J'ai le fichier qui a été correctement généré en français, puis je vois absolument rien en arabe et en anglais... Et c'est là que les neurones se connectent, le mot légende s'écrit pas pareil en fonction de la langue... Et oui c'est évident dit comme ça mais fallait y penser! Du coup, je ne savais pas trop comment m'y prendre pour faire que le script reconnaisse les trois mots pour chaque langue. J'ai pensé à faire une expression régulière, ce qui pourrait fonctionner avec l'anglais et le français mais je savais vraiment pas comment faire pour le mot en arabe... J'étais bloquée, du coup j'avoue, j'ai utilisé ChatGPT... Et j'ai découvert qu'on pouvait faire un dictionnaire en bash comme en Python!!! Du coup c'est ce que j'ai utilisé pour reconnaître les mots pour chaque langue. Donc le dictionnaire associe chaque langue à son mot clé correspondant ce qui adapte automatiquement le mot recherché en fonction de la langue traitée. Et après pour chaque langue je récupère le dump et j'applique grep dessus avec PLEIN d'options parce que sinon y'avait toujours un soucis... -a qui force à traiter les fichiers comme du texte brut. -i (le classique) qui ignore la casse. -C 1 qui affiche une ligne de contexte avant et après chaque occurrence trouvée. Au début comme je traitais chaque url dans le même fichier on y voyait rien car tous les urls étaient à la suite du coup j'ai mis sed pour mettre en évidence avec des chevron chaque occurence du mot légende dans chaque langue.</p>

               <p><h6 class="section-title">Le 30/12/2024 (Mickaëla)</h6> La mission de ce jour a été de faire qu'il y ait un fichier par URL pour chaque script, car comme la fiche d'exercicel'indiquait, après avoir crée les scripts il fallait mettre les résultats dans une nouvelle colonne dans le tableau. Et dans cette colonne il devait yavoir un lien pour chaque fichier résultat (la page aspirée, son dump, son contexte etc...). Alors je trouvais ça bizarre d'avoir 50 fois le même lien vers le même fichier et de devoir scroller à l'infini pour voir l'url correspondant... Il fallait donc créer un fichier distinct pour chaque URL, en utilisant un index numérique pour les identifier. On établit donc un compteur dans la boucle qui s'incrémente de 1 pour chaque URls traitée. Après il fallait générer les tableaux donc j'ai gardé la structure initiale de l'exercice du miniprojet individuel avec les codes http, l'encodage etc, et j'ai rajouté les colonnes nécessaires. Une question qui m'est venue concernait l'affichage des fichiers .txt tels que les dumps et les contextes dans un navigateur web. Je pensais qu'il fallait les convertir en html mais je n'étais pas sûre que ce soit la bonne chose à faire. Puis j'ai demandé à une M2 de m'expliquer comment elle s'y était prise l'an dernier et en fait les fichiers textes s'affichent aussi dans le web... Donc oui je me prenais la tête pour rien :)</p>

                <p><h6 class="section-title">Le 31/12/2024 (Mickaëla)</h6>Avant le réveillon du nouvel an, j'ai continué le travail de la veille en modifiant les scripts aspirations, contextes, concordancier pour avoir un fichier par url puis j'ai modifié le script générant les tableaux pour qu'ils affichent le fichier correspondant à leur url. Je me suis ensuite attaquée aux exercices PALS. La difficulté majeure a été de créer un script rendant les corpus dumps et contextes adaptés au traitement textométrique des scripts cooccurrents et partition. La tokenisation a été assez simple avec [[:alpha:]] qui reconnait tous les caractères ASCII de l'anglais, mais le soucis majeur résidait dans les problèmes d'encodage/regex pour le français et l'arabe. En effet, mon éditeur de texte ne reconnaissait pas les caractères diacrités du français et les caractères de l'arabe malgré la lecture des fichiers en UTF-8 qui fonctionnent normalement avec ces deux langues. J'ai demandé à Ihsane (étudiante de notre promo) et une m2, Kehina (merci à elles) de m'aider par rapport à ce soucis. Elles m'ont aiguillé en me proposant plusieurs regex pour reconnaître les caractères arabes: ا-ي. et أسطورة|أسطورات|أسطورتين|الأسطورة|الأسطورات|الأسطورتين et pour le français accentués : a-zàâçéèêëîïôûùüÿñæœ. Mais cela ne fonctionnait pas. J'ai donc décidé de régler ce soucis pour l'année prochaine :)</p>

                <p><h6 class="section-title">Le 31/12/2024 (Oumaya)</h6>Aujourd'hui même si je n'étais pas encore très bien j'ai décider de me forcé à travailler quitte à ne pas être bien, car l'angoisse me rongeais. J'ai donc regardée ce qu'on fait mes camarades et de là j'ai continué le travail. J'ai regardée tous les scripts pour voir ce qu'elles avaient compléter etc.. et de la j'ai cmmencée à aportée les petites modifications que je jugeais nécessaire pour chaque script.Par exemple j'ai modifier le script compte pour qu'ils soient plus adapté aux trois langues et ait un meilleur format.J'ai ensuite attaqué le script qui génère les tableaux j'ai régler quelques aspects technique et ensuite je me suis attaquée au CSS de ce script pour que le tableau suivant le même style que notre page et puisse être plus agréable à lire. Après toutes ces modifications je me suis rendu compte qu'il était dèjà 5h du matin (nuit blanche ^^"), que une longue journée m'attendais le lendemin donc j'ai chosi de m'arrêter . </p>

                <p><h6 class="section-title">Le 1/01/2025 (Mickaëla)</h6> BONNE ANNEE 2025!!!!!!!!!! Rien de mieux pour fêter ça que de galérer sur des problèmes d'encodage et de regex :). Non je rigole, j'étais trop fatiguée pour me battre avec ça dès le réveil donc j'ai considéré que c'était un problème pour la moi de plus tard. J'ai avancé un peu en testant le script PALS sur le corpus de ma langue qui est le seul pour qui la tokenisation a fonctionné. J'ai regardé les consignes d'utilisations du script avec -h et j'ai joué un peu avec. J'ai vu qu'on pouvait émuler itrameur avec le script. Alors je ne suis pas une grande linguiste donc j'avoue que je ne comprenais pas tout au résultat mais je savais qu'itrameur était un outil utilisé par les promos des années précédentes donc j'ai décidé de tester moi aussi pour l'analyse. Puis je me suis remise sur le problème des regex/encodage.. Pour une raison obscure j'ai commencé à me dire que c'était peut être un problème avec les scripts dumps et contextes... J'ai donc vérifié et je me suis rendue compte d'un autre problème, les contextes ne récupèrent que le singulier "legend" pareil pour le français et je suppose pareil pour l'arabe (je sais pas lire l'arabe :/). Ce qui est bizarre c'est que lorsque je lançais grep sur le terminal, ça fonctionnait à moitié... Bref trop de problèmes j'ai donc décdié de me lancer sur d'autres projet à rendre dans d'autres matières pour la semaine qui a suivi.</p>

                <p><h6 class="section-title">Le 1/01/2025 (Oumaya)</h6>En vous souhaitant une bonne année 2025 ^^ !! Alors aujourd'hui j'ai galérer à essayer de Regex toutes la journée j'ai essayée de reprendre le problème sous tous les angles de comprendre comment résoudre ce souci mais rien y fait je ne comprend rien. Je décide donc de passer à autre chose et donc de régler le concordancier car il y'avait un petit souci d'affichage et de rajouter le CSS por que lui aussi puisse suivre le même esthétique que notre page et que ce soit donc plus agrèable à lire. J'ai aussi rajouter la partie où les membres du groupe pourront ce présenter avec des avatars et un texte sur notre page. Et je n'en ai parlé précédement mais à chaque fois que voulais push quelque chose ou pull il y'avait TOUJOURS !! des problèmes de CONFLITS et donc à chaque fois c'était le parcours du combattant pour pouvoir push ce que j'ai fait sans perdre mon travaille ou faire des problèmes pour les autres membre du groupe (déregler leurs travaille), et ceux malgré notre efforts d'organisation avec le groupe Whatsapp.Ça été vraiment dure et c'est une grosse source d'angoisse pour moi (qui est déjà de nature angoissée) et parfois j'en perdais la volonté de travailler et donc parfois je remettais mes push au lendemain >.< , ce qui explique mon nombre de commit car je mettais à chaque fois mon travail de coté sur mon ordinateur le temps de régler les conflits et ensuite tous commits en une seule fois.) </p>

                <p><h6 class="section-title">Le 7-8/01/2025 (Mickaëla)</h6>De retour sur PPE après une semaine de souffrance sur d'autres projets :(. Toujours le même soucis sur la tokenisation du corpus français et arabe... Avant j'essaie de quand même de régler le soucis avec grep dans le script contexte en le remplaçant par egrep car dans le terminal egrep reconnaissait la regex legends? et légendes?. Mais une fois dans le script, quand je le lançais puis que je lançais le concordancier j'avais toujours le contexte droit qui me donnait un "s" en premier mot... Alors en soit j'ai quand même la ligne d'après, mais je trouve ça un peu dommage car la commande fonctionne vraiment dans le terminal avec le français et l'anglais en tout cas.. J'abandonne le sujet pour retourner sur la tokenisation, je suis désespérée je trouve pas de soluce donc je fais à appel à ChatGPT qui me propose la commande perl sauf que j'y comprends rien donc j'abandonne vite ce sujet aussi... Finalement je me lance dans l'amélioration du site qui est une partie mafoi très satisfaisante et esthétique. J'ai rajouter une page à propos pour donner des informations sur les membres du projet. J'ai cherché comment rajouter un menu déroulant puis je l'ai ajouté aux balise. Je commence la rédaction de la présentation etc... Voilà pour ce jour.</p>

                <p><h6 class="section-title">Du 5/01/25 au 9/01/2025 (Oumaya)</h6>Pendant cette pèriode j'ai tout essayée pour arranger les soucis de la tokenisation du corpus français et arabe... J'ai essayer de demander de l'aide que ce soit à des amis, les membres de ma famille forts en informatique (mon cousin) et même une doctorante issue de notre master mais rien y fait on ne comprends pas qu'est-ce qui cloche avec la regex. Et entre temps j'ai eu d'énorme soucis de chemin aussi et donc j'ai dû régler cela aussi car à chasque fois que j'essayais d'éxecuter le script makepalscorpus cela me mettais "abort" et no such directions.Je vous avoue que j'ai eu extrêmement peur car on était plus qu'à quelque jours du rendu et je n'avais toujours pas de solution #angoissée_à_mort. Et je complète aussi ma liste d'urls.</p>

                <p><h6 class="section-title">Le 9/01/2025 (Mickaëla)</h6>Prise d'un élan d'énergie dans la nuit du 8 au 9 j'ai décidé de compléter ma liste d'urls! Puis j'ai repris l'analyse linguistique dans la journée. Grâce à Ihsane j'ai découvert l'outil voyant tools qui permet de faire des nuages de mots interactifs! C'est super joli donc j'ai voulu tester sur mes corpus. Or, il y avaient plusieurs soucis (c'est pas drôle sinon), d'abord le site n'acceptaient pas ni mes dumps ni mes contextes. Ils se trouvaient que certain de mes fihciers avaient des données non textuelles . J'ai utilisé la commande file dans mon terminal pour identifier les fichiers posant problème (ça m'indiquait data dans le terminal) et il se trouvait qu'il y avait deux lien qui n'était pas des fichier de type html ou txt. J'ai donc remplacé les urls posant problème. Puis j'ai eu le soucis des "parasites" dans mon nuage qui rendait le tout assez peu pertinent. Cela correspondaient à tout ce qui est "autour" du sujet principal du site par exemple si c'est un article,les liens vers d'autres articles, les liens vers d'autres pages wikipedia etc... Donc j'ai essayé de trouvé des techniques pour nettoyer les fichiers aspirations ou dump avec sed par exemple : echec car il n'y avait pas qu'une forme récurrente de données parasites, mais tout plein et je savais pas comment en faire une expression à reconnaître... ChatGPT m'a proposé des commandes comme html2text : ça marche pas. Je me suis rappelée de la commande awk qu'on a mentionnée en cours mais j'ai cru comprendre en cours que c'est un truc pour les grands donc j'ai pas osé utiliser. Finalement j'ai juste cat * les résultats du script dump et j'ai essayé d'enlever les données à la main le plus possible... C'était LONG. Mais ça a plus ou moins marché car maintenant mon nuage est tout beau :). J'ai continué à essayer de régler le soucis des contextes et de tokenisation, sans résultats :(. J'ai aussi rajouté des pages manquantes comme le journal et l'analyse linguistique dans le site etc...

                <p><h6 class="section-title">Le 10/01/2025 (Mickaëla)</h6>Aujourd'hui, je me suis attelée à l'interprêtation et à la rédaction des résultats des scripts cooccurrent et partition. La difficulté ici a été d'utiliser le script partition pour les contextes car cela me disait qu'il n'y avait pas assez de données? Ce qui est bizarre car pour les dumps je n'ai pas eu de soucis j'ai donc décidé de me concentrer sur les cooccurences. J'ai surtout fait de l'écriture et de la mise en forme des pages. J'ai aussi ajouté ma description dans le a propos du site.Il ne manque plus que d'ajouter la section scripts au site et de les expliquer et puis je pense que j'arrive à la fin de mon travail sur ce projet.

                <p><h6 class="section-title">Le 10/01/2025 (Oumaya)</h6>Aujourd'hui, j'ai pris le temps de regardée les petites modification qu'a fait ma camrade au site et j'ai continuée aussi les modification que j'ai jugée nécessaire j'ai aussi compléter ma présentation dans la page à propos et de remplacer mon image. Je me suis ensuite remis sur le problème de regex mais j'ai compris que je n'arriverais pas à trouver de solution et je commençais de plus en plus à me pencher vers la solution de faire mon analyse avec voyant-tools , je suis vraiment désolée !!! >< j'ai tout essyer mais rien y fait</p>

                <p><h6 class="section-title">Le 11/01/2025 (Mickaëla)</h6> Alors il est 3h30 et je viens d'avoir une illumination par rapport au script contexte qui ne reconnait que legend au singulier! Peut être que le soucis n'est pas le script contexte au final mais le concordancier!!!! En effet comme egrep fonctionne dans le terminal, ça veut dire que mes contextes (et j'ai vérifié) ont bien soit legend ou legends. Or je vérifie toujours le concordancier sur le site car c'est plus simple de consulter ce tableau plutôt que de chercher dans le fichier texte de contexte. Et c'est là bas que je voyais le soucis!!!! Donc il est temps de jeter un oeil dessus #insomnie. Alors dans la nuit j'ai effectivement réussi à faire que le concordancier récupère les variations de notre mot d'étude avec egrep mais les résultats du tableau récupéraient des choses bizarres aussi donc j'ai préféré en rester avec la première version... Je trouve ça dommage car la commande egrep -i -E -a fonctionne dans le terminal donc je n'arrive pas à comprendre pourquoi ce n'est pas le cas dans le concordancier. Dans la journée, j'ai surtout finalisé les derniers détails de ma partie et corrigé les bugs du grand script appelant tous les autres.</p>

                <p><h6 class="section-title">Le 11/01/2025 (Oumaya)</h6>Aujourd'hui, je me suis attaquée à l'interprêtation et à la rédaction des résultats de voyant tools finalement car après beaucoup de tentative avec le script makepals celui-ci continuait à me faire des afichage bizarre pour les diacrités du style "l√©gende".Et donc je préfére au moins rendre une analyse, quelque chose plutôt que rien. Encore une fois vraiment désolée !!! et donc j'ai créer la page d'analyse du français à partir des résultats obtenues avec voyant-tools. J'ai aussi créer le script générale qui permet d'appeller tous les autres script en un et de faire directement avec ce script du coup, j'avais rejoutée toute mes urls donc j'ai pu tester mon script et il marchait bien et donc j'ai push mes update. On a ensuite ajouter la section scripts au site qui permet d'exmplquer les scripts utilisés dans ce projet et j'ai fait quelque modifications sur cette page et surtout j'ai veiller à ce que l'ésthetique de celle-ci suit le reste.J'ai tenu à faire tout ce qui était en mon pouvoir pour la langue dont je suis chargé et même pour le site de manière générale et veillée à faire toute les tâches qu'on m'a donné lors de la répartition (et autres bien sûr lorsque je voyais quelque chose à faire je le faisais c'est tout ^^).Et je pense qu'avec ceci j'arrive à la fin de mon travail sur ce projet, en tout cas j'ai fait de mon mieux à mon niveau jusqu à la fin (surtout avec tous ces problème de conflits git et tout les traveaux que j'ai perdue au début lorqu'une autre personne mettais (push) sont travaille), ça été très angoissant mais j'éspère que vous serez satisfait de notre site et de notre travail (encore désolé pour l'analyse).</p>

                <p><h6 class="section-title">Le 12/01/2025 (Mickaëla)</h6>Aujourd'hui j'ai simplement mis à jour mon journal et corrigé les fautes d'orthographes (désolée si y'en a encore on fait ce qu'on peut). J'ai aussi ajouté une comparaison entre les nuages de mots du dump et du contexte. Voilà tout!</p>
                 
                 <p><h6 class="section-title">Le 12/01/2025 (Oumaya)</h6>Aujourd'hui, je finie la rédaction de certain passage de ce journale car j'ai eu beaucoup de mal certain jour à bien écrire (car trop angoissée, bien sur on ne peut pas écrire en détaille tout ce que l'on a fait dans ce journale)et je pense que cela marque la fin de mon travaille sur ce projet. Il me restera plus qu'à déployé le site et archivé . Merci à vous d'avoir pris le temps de lire ce journale et je vous souhaite une bonne semaine avant la prochaine rentrée ^^.</p>

                 <p><h6 class="section-title">Zeinab</h6>malheuresement, j'ai mal compris le concept du journal... je n'ai pas écrit tout les jours mais c'est pas grave... je vais vous récapituler mon parcours et mon ressenti durant ce travail... alors les taches à faire n'étais si évidentes que ça... j'avais pour taches dés le départ de faire la plupart des scripts dont (la validation des urls, concordancier et le make pals...) que mes collégues ont bien sur modifié au fur et à mesure du travail afin d'adapter à leur langues. malheuresement, je n'ai pas eu beaucoup de sources pour le mot légende en arabe d'ou le peu d'urls que j'ai, ce qui m'a beaucoup étonné car je ne m'attendais pas à ce que j'ai peu de ressources. je rencocntre acctuellement de gros problèmes de regex avec ce mots et d'encondage à cause du script make pals... c'est un peu la panique je ne vais pas vous mentir parce que cela m'empeche à faire mon analyse linguistique, j'essaye de trouver une solution depuis un moment... si ça ne marche toujours pas je me contenterai que de voyant tools...j'ai créée également une page web explicatif des script qui permet de mettre au clair tout notre travail. Je reconnais que le nombre de commits dans mon dépôt Git est relativement faible. Cependant, cela ne reflète pas pleinement le travail que j’ai accompli. J’ai rencontré des contraintes liées à un déplacement à l’étranger, ce qui m’a empêché de travailler régulièrement chaque jour. Malgré cette interruption, j’ai tenu mes engagements et accompli les tâches qui m’ont été assignées dans le cadre de la répartition convenue avec mes collègues.</p>

            </section>


        <footer>
            <p>Fait par Oumaya Chelbi, Mickaëla Masrodicasa et Zeinab Omar.<br>
                <a href="https://github.com/mickaela-mstr/PPE_groupe" target="_blank">Voir le projet sur GitHub</a>
            </p>
        </footer>
    </div>
</body>
</html>

